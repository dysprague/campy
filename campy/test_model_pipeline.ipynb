{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, time, csv, logging\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "#import tensorflow as tf\n",
    "from scipy import io as sio\n",
    "import cv2\n",
    "import traceback\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorrt \n",
    "\n",
    "from tensorflow.python.compiler.tensorrt import trt_convert as tf_trt\n",
    "from tensorflow.python.saved_model import tag_constants\n",
    "from typing import List, Optional, Text\n",
    "\n",
    "from time import perf_counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_frames(video_path, fidxs=None, grayscale=True):\n",
    "    \"\"\"Read frames from a video file.\n",
    "    \n",
    "    Args:\n",
    "        video_path: Path to MP4\n",
    "        fidxs: List of frame indices or None to read all frames (default: None)\n",
    "        grayscale: Keep only one channel of the images (default: True)\n",
    "    \n",
    "    Returns:\n",
    "        Loaded images in array of shape (n_frames, height, width, channels) and dtype uint8.\n",
    "    \"\"\"\n",
    "    vr = cv2.VideoCapture(video_path)\n",
    "    if fidxs is None:\n",
    "        fidxs = np.arange(vr.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    frames = []\n",
    "    for fidx in fidxs:\n",
    "        vr.set(cv2.CAP_PROP_POS_FRAMES, fidx)\n",
    "        img = vr.read()[1]\n",
    "        if grayscale:\n",
    "            img = img[:, :, [0]]\n",
    "        frames.append(img)\n",
    "    return np.stack(frames, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_available_gpus() -> List[tf.config.PhysicalDevice]:\n",
    "    \"\"\"Return a list of available GPUs.\"\"\"\n",
    "    return tf.config.get_visible_devices(\"GPU\")\n",
    "\n",
    "def disable_preallocation():\n",
    "    \"\"\"Disable preallocation of full GPU memory on all available GPUs.\n",
    "\n",
    "    This enables memory growth policy so that TensorFlow will not pre-allocate all\n",
    "    available GPU memory.\n",
    "\n",
    "    Preallocation can be more efficient, but can lead to CUDA startup errors when the\n",
    "    memory is not available (e.g., shared, multi-session and some *nix systems).\n",
    "\n",
    "    See also: enable_gpu_preallocation\n",
    "    \"\"\"\n",
    "    for gpu in get_available_gpus():\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "class OptimizedModel():\n",
    "    def __init__(self, saved_model_dir = None):\n",
    "        self.loaded_model_fn = None\n",
    "        \n",
    "        if not saved_model_dir is None:\n",
    "            self.load_model(saved_model_dir)\n",
    "            \n",
    "    \n",
    "    def predict(self, input_data, batch_size=None): \n",
    "        if self.loaded_model_fn is None:\n",
    "            raise(Exception(\"Haven't loaded a model\"))\n",
    "            \n",
    "        if batch_size is not None:\n",
    "            all_inds = np.arange(len(input_data))\n",
    "            all_preds = []\n",
    "            for inds in np.array_split(all_inds, int(np.ceil(len(all_inds) / batch_size))):\n",
    "                all_preds.append(self.predict(input_data[inds]))\n",
    "            return all_preds\n",
    "                \n",
    "#         x = tf.constant(input_data.astype('float32'))\n",
    "        x = tf.constant(input_data)\n",
    "        labeling = self.loaded_model_fn(input=x)\n",
    "        try:\n",
    "            preds = labeling['predictions'].numpy()\n",
    "        except:\n",
    "            try:\n",
    "                preds = labeling['probs'].numpy()\n",
    "            except:\n",
    "                try:\n",
    "                    preds = labeling[next(iter(labeling.keys()))]\n",
    "                except:\n",
    "                    raise(Exception(\"Failed to get predictions from saved model object\"))\n",
    "        return preds\n",
    "    \n",
    "    def load_model(self, saved_model_dir):\n",
    "        saved_model_loaded = tf.saved_model.load(saved_model_dir, tags=[tag_constants.SERVING])\n",
    "        wrapper_fp32 = saved_model_loaded.signatures['serving_default']\n",
    "        \n",
    "        self.loaded_model_fn = wrapper_fp32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = '../models/250421_183045.single_instance.n=8280.trt.FP32'\n",
    "model = OptimizedModel(model_path)\n",
    "\n",
    "video_path = '../test/example.mp4'\n",
    "\n",
    "t0 = perf_counter()\n",
    "\n",
    "frame = read_frames(video_path, fidxs=[0], grayscale=False)\n",
    "\n",
    "t1 = perf_counter()\n",
    "\n",
    "with tf.device('/CPU:0'):\n",
    "    imresized = tf.transpose(tf.cast(tf.image.resize(frame, size=[600,960], method='bilinear', preserve_aspect_ratio=False, antialias=False,), tf.float32), perm=[2,0,1])\n",
    "#ready for processing \n",
    "\n",
    "t2 = perf_counter()\n",
    "\n",
    "disable_preallocation()\n",
    "\n",
    "with tf.device('/GPU:0'):\n",
    "    gpu_tensor = tf.cast(tf.variable(initial_vale=tf.zeros((3,3,600,960))), tf.float32)\n",
    "\n",
    "model.predict(gpu_tensor) #initialize graph \n",
    "\n",
    "t3 = perf_counter()\n",
    "\n",
    "for i in range(3):\n",
    "    gpu_tensor[i].assign(frame) # check how long to load frames onto GPU\n",
    "\n",
    "t4 = perf_counter()\n",
    "\n",
    "output = model.predict(gpu_tensor)\n",
    "\n",
    "t5 = perf_counter()\n",
    "\n",
    "print(f'Read frame time: {(t1-t0)*1000} msec')\n",
    "print(f'CPU im preprocessing time: {(t2-t1)*1000} msec')\n",
    "print(f'Model and gpu tensor initialization time: {(t3-t2)*1000} msec')\n",
    "print(f'Place preprocessed frames on GPU time: {(t4-t3)*1000} msec')\n",
    "print(f'Model prediction time: {(t5-t4)*1000} msec')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert model output to keypoints: peak finding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_global_peaks_rough(\n",
    "    cms: tf.Tensor, threshold: float = 0.1\n",
    ") -> Tuple[tf.Tensor, tf.Tensor]:\n",
    "    \"\"\"Find the global maximum for each sample and channel.\n",
    "\n",
    "    Args:\n",
    "        cms: Tensor of shape (samples, height, width, channels).\n",
    "        threshold: Scalar float specifying the minimum confidence value for peaks. Peaks\n",
    "            with values below this threshold will be replaced with NaNs.\n",
    "\n",
    "    Returns:\n",
    "        A tuple of (peak_points, peak_vals).\n",
    "\n",
    "        peak_points: float32 tensor of shape (samples, channels, 2), where the last axis\n",
    "        indicates peak locations in xy order.\n",
    "\n",
    "        peak_vals: float32 tensor of shape (samples, channels) containing the values at\n",
    "        the peak points.\n",
    "    \"\"\"\n",
    "    # Find row maxima.\n",
    "    max_img_rows = tf.reduce_max(cms, axis=2)\n",
    "    argmax_rows = tf.reshape(tf.argmax(max_img_rows, axis=1), [-1])\n",
    "\n",
    "    # Find col maxima.\n",
    "    max_img_cols = tf.reduce_max(cms, axis=1)\n",
    "    argmax_cols = tf.reshape(tf.argmax(max_img_cols, axis=1), [-1])\n",
    "\n",
    "    # Construct sample and channel subscripts.\n",
    "    channels = tf.cast(tf.shape(cms)[-1], tf.int64)\n",
    "    total_peaks = tf.cast(tf.shape(argmax_cols)[0], tf.int64)\n",
    "    sample_subs = tf.range(total_peaks, dtype=tf.int64) // channels\n",
    "    channel_subs = tf.math.mod(tf.range(total_peaks, dtype=tf.int64), channels)\n",
    "\n",
    "    # Gather subscripts.\n",
    "    peak_subs = tf.stack([sample_subs, argmax_rows, argmax_cols, channel_subs], axis=1)\n",
    "\n",
    "    # Gather values at global maxima.\n",
    "    peak_vals = tf.gather_nd(cms, peak_subs)\n",
    "\n",
    "    # Convert to points form (samples, channels, 2).\n",
    "    peak_points = tf.reshape(\n",
    "        tf.cast(tf.stack([argmax_cols, argmax_rows], axis=-1), tf.float32),\n",
    "        [-1, channels, 2],\n",
    "    )\n",
    "    peak_vals = tf.reshape(peak_vals, [-1, channels])\n",
    "\n",
    "    # Mask out low confidence points.\n",
    "    peak_points = tf.where(\n",
    "        tf.expand_dims(peak_vals, axis=-1) < threshold,\n",
    "        x=tf.constant(np.nan, dtype=tf.float32),\n",
    "        y=peak_points,\n",
    "    )\n",
    "\n",
    "    return peak_points, peak_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single instance layer \n",
    "def call(self, data):\n",
    "        \"\"\"Predict instance confidence maps and find peaks.\n",
    "\n",
    "        Args:\n",
    "            inputs: Full frame images as a `tf.Tensor` of shape\n",
    "                `(samples, height, width, channels)` or a dictionary with key:\n",
    "                `\"image\"`: Full frame images in the same format as above.\n",
    "\n",
    "        Returns:\n",
    "            A dictionary of outputs grouped by sample with keys:\n",
    "\n",
    "            `\"instance_peaks\"`: The predicted peaks of shape `(samples, 1, nodes, 2)`.\n",
    "            `\"instance_peak_vals\": The peak confidence values of shape\n",
    "            `(samples, 1, nodes)`.\n",
    "\n",
    "            If the `return_confmaps` attribute is set to `True`, the output will also\n",
    "            contain a key named `\"confmaps\"` containing a `tf.Tensor` of shape\n",
    "            `(samples, output_height, output_width, 1)` containing the confidence maps\n",
    "            predicted by the model.\n",
    "        \"\"\"\n",
    "        if isinstance(data, dict):\n",
    "            imgs = data[\"image\"]\n",
    "        else:\n",
    "            imgs = data\n",
    "        imgs = self.preprocess(imgs)\n",
    "        preds = self.keras_model(imgs)\n",
    "        offsets = None\n",
    "        if isinstance(preds, list):\n",
    "            cms = preds[self.confmaps_ind]\n",
    "            if self.offsets_ind is not None:\n",
    "                offsets = preds[self.offsets_ind]\n",
    "        else:\n",
    "            cms = preds\n",
    "        if self.offsets_ind is None:\n",
    "            peaks, peak_vals = sleap.nn.peak_finding.find_global_peaks(\n",
    "                cms,\n",
    "                threshold=self.peak_threshold,\n",
    "                refinement=self.refinement,\n",
    "                integral_patch_size=self.integral_patch_size,\n",
    "            )\n",
    "        else:\n",
    "            peaks, peak_vals = sleap.nn.peak_finding.find_global_peaks_with_offsets(\n",
    "                cms,\n",
    "                offsets,\n",
    "                threshold=self.peak_threshold,\n",
    "            )\n",
    "\n",
    "        # Adjust for stride and scale.\n",
    "        peaks = peaks * self.output_stride\n",
    "        if self.input_scale != 1.0:\n",
    "            # Note: We add 0.5 here to offset TensorFlow's weird image resizing. This\n",
    "            # may not always(?) be the most correct approach.\n",
    "            # See: https://github.com/tensorflow/tensorflow/issues/6720\n",
    "            peaks = (peaks / self.input_scale) + 0.5\n",
    "\n",
    "        out = {\n",
    "            \"instance_peaks\": tf.expand_dims(peaks, axis=1),\n",
    "            \"instance_peak_vals\": tf.expand_dims(peak_vals, axis=1),\n",
    "        }\n",
    "        if self.return_confmaps:\n",
    "            out[\"confmaps\"] = cms\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get skeleton from some mat/slp file\n",
    "# Use for live plotting skeleton "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
